# SAFE-T2107: AI Model Poisoning via MCP Tool Training Data Contamination
# This rule detects potential AI Model Poisoning via MCP Tool Training Data Contamination attempts
# Note: This is an example rule. Attackers continuously develop new techniques.

title: AI Model Poisoning via MCP Tool Training Data Contamination Detection
id: d7b2f580-f69f-49ba-9a95-ecb6589c763e
status: experimental
description: Detects potential AI Model Poisoning via MCP Tool Training Data Contamination
  attempts in MCP environments
author: SAFE-MCP Team
date: '2025-09-13'
references:
- https://github.com/safe-mcp/techniques/SAFE-T2107
logsource:
  product: mcp
  service: tool_invocation
detection:
  selection:
    tool_name|contains:
    - '*tools/call*'
    - '*method*: *tools/call*'
    - '*tool_name*'
  condition: selection
falsepositives:
- Legitimate operations that match detection patterns
- Authorized administrative activities
- Security testing and research activities
level: high
tags:
- attack.resource_development
- safe.t2107
- attack.t1574
